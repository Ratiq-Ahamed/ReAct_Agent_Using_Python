{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\agent projects\\react_agent\\lib\\site-packages (from groq) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\agent projects\\react_agent\\lib\\site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\agent projects\\react_agent\\lib\\site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in d:\\agent projects\\react_agent\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\agent projects\\react_agent\\lib\\site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\agent projects\\react_agent\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\agent projects\\react_agent\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in d:\\agent projects\\react_agent\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\agent projects\\react_agent\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\agent projects\\react_agent\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\agent projects\\react_agent\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\agent projects\\react_agent\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "Successfully installed distro-1.9.0 groq-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, have gained significant attention in recent years due to their importance in various applications. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Scalability**: Fast language models can process large amounts of text data quickly, making them suitable for applications that require real-time processing, such as chatbots, virtual assistants, and language translation systems.\n",
      "2. **Resource Efficiency**: Traditional language models are computationally expensive and require significant resources (e.g., memory, CPU, and GPU). Fast language models, on the other hand, are designed to be lightweight and can run on lower-end hardware, making them more accessible to a wider range of users.\n",
      "3. **Edge Computing**: With the increasing adoption of edge computing, fast language models can be deployed on edge devices, such as smartphones, smart home devices, and IoT devices, enabling real-time processing and reducing latency.\n",
      "4. **Real-time Applications**: Fast language models are essential for real-time applications, such as:\n",
      "\t* Speech recognition: Fast language models can recognize spoken language in real-time, enabling applications like voice assistants and speech-to-text systems.\n",
      "\t* Language translation: Fast language models can translate text in real-time, making them suitable for applications like instant messaging and online collaboration.\n",
      "\t* Sentiment analysis: Fast language models can analyze sentiment in real-time, enabling applications like customer service chatbots and social media monitoring.\n",
      "5. **Improved User Experience**: Fast language models can provide a better user experience by:\n",
      "\t* Reducing latency: Fast language models can respond quickly to user input, reducing the time it takes to process and respond to user queries.\n",
      "\t* Enabling conversational interfaces: Fast language models can power conversational interfaces, such as chatbots and voice assistants, making it easier for users to interact with devices and services.\n",
      "6. **Advancements in AI**: Fast language models can accelerate the development of artificial intelligence (AI) and machine learning (ML) applications by:\n",
      "\t* Enabling faster training: Fast language models can be trained quickly, allowing researchers to iterate and improve models faster.\n",
      "\t* Improving model accuracy: Fast language models can be used to fine-tune and improve the accuracy of larger language models.\n",
      "7. **Cost-Effective**: Fast language models can reduce costs by:\n",
      "\t* Reducing computational resources: Fast language models require less computational power, reducing the need for expensive hardware and infrastructure.\n",
      "\t* Enabling cloudless processing: Fast language models can be deployed on edge devices, reducing the need for cloud-based processing and associated costs.\n",
      "\n",
      "In summary, fast language models are crucial for various applications that require real-time processing, scalability, and resource efficiency. They can improve user experience, accelerate AI and ML development, and reduce costs, making them an essential component of modern language processing systems.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "wikipedia:\n",
    "e.g. wikipedia: Django\n",
    "Returns a summary from searching Wikipedia\n",
    "\n",
    "Always look things up on Wikipedia if you have the opportunity to do so.\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the capital of France?\n",
    "Thought: I should look up France on Wikipedia\n",
    "Action: wikipedia: France\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: France is a country. The capital is Paris.\n",
    "Thought: I think I have found the answer\n",
    "Action: Paris.\n",
    "You should then call the appropriate action and determine the answer from the result\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: The capital of France is Paris\n",
    "\n",
    "Example session\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth on Wikipedia\n",
    "Action: wikipedia : mass of earth\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: mass of earth is 1,1944×10e25\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import httpx\n",
    "def wikipedia(q):\n",
    "    return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": q,\n",
    "        \"format\": \"json\"\n",
    "    }).json()[\"query\"][\"search\"][0][\"snippet\"]\n",
    "#\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(max_iterations=20, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"wikipedia\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            print(action)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up Abdul Kalam on Wikipedia to find out who he is.\n",
      "\n",
      "Action: wikipedia: Abdul Kalam \n",
      "PAUSE\n",
      "[('wikipedia', 'Abdul Kalam ')]\n",
      "Observation: Avul Pakir Jainulabdeen <span class=\"searchmatch\">Abdul</span> <span class=\"searchmatch\">Kalam</span> BR (/ˈəbdʊl <span class=\"searchmatch\">kəˈlɑːm</span>/ ; 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served\n",
      "Thought: I think I have found the answer, Abdul Kalam was an Indian aerospace scientist and statesman.\n",
      "\n",
      "Action: He was an Indian aerospace scientist and statesman. \n",
      "(No action needed, I have the answer)\n",
      "\n",
      "Answer: Abdul Kalam was an Indian aerospace scientist and statesman.\n"
     ]
    }
   ],
   "source": [
    "loop(query=\"Who is Abdul kalam in? in 1 sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I'm not familiar with the decathlon company, I should look it up on Wikipedia.\n",
      "Action: wikipedia: Decathlon \n",
      "PAUSE\n",
      "[('wikipedia', 'Decathlon ')]\n",
      "Observation: The <span class=\"searchmatch\">decathlon</span> is a combined event in athletics consisting of 10 track and field events. The word &quot;<span class=\"searchmatch\">decathlon</span>&quot; was formed, in analogy to the word &quot;pentathlon&quot;\n",
      "Thought: This doesn't seem to be what I was looking for, it seems to be describing an athletic event.\n",
      "Thought: I think I need to look up Decathlon again, but this time as a company.\n",
      "Action: wikipedia: Decathlon (company)\n",
      "PAUSE\n",
      "[('wikipedia', 'Decathlon (company)')]\n",
      "Observation: <span class=\"searchmatch\">Decathlon</span> (French pronunciation: [dekatlɔ̃]) is a French sporting goods retailer. With over 2,080 stores in 78 countries and regions (2023), it is the\n",
      "Thought: Ah, I've found it! Decathlon is a French sporting goods retailer.\n",
      "Action: (no action needed, I have the answer)\n",
      "Answer: Decathlon is a French sporting goods retailer.\n"
     ]
    }
   ],
   "source": [
    "loop(query=\"What does decathlon company do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
